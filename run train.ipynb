{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a349beda",
   "metadata": {},
   "source": [
    "#### Ausführung von Run befehl zum Starten des Trainingsprozesses; der Task parameter gibt an welcher datensatz aus dem Ordner /doduo/data ausgewählt wird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aab16fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args={\"shortcut_name\": \"bert-base-uncased\", \"max_length\": 256, \"batch_size\": 1, \"epoch\": 30, \"random_seed\": 1, \"num_classes\": 78, \"multi_gpu\": false, \"fp16\": false, \"warmup\": 0.0, \"lr\": 0.001, \"tasks\": [\"gittables_30\"], \"colpair\": false, \"train_ratios\": [], \"from_scratch\": false, \"single_col\": false, \"shuffle_cols\": false, \"sport_domains\": [\"baseball\"]}\n",
      "model/gittables_30_mosato_bert_bert-base-uncased-bs1-ml-256__gittables_30-1.00_scFalse_rs1\n",
      "[1214]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultiOutputClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForMultiOutputClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultiOutputClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultiOutputClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gittables_30']\n",
      "30\n",
      "30\n",
      "Data loading completed\n",
      "411\n",
      "start of training\n",
      "0  Epoch  0  K\n",
      "411\n",
      "After Batches\n",
      "Before Validation\n",
      "calculate F1 score\n",
      "1  Epoch  0  K\n",
      "411\n",
      "After Batches\n",
      "Before Validation\n",
      "calculate F1 score\n",
      "2  Epoch  0  K\n",
      "411\n",
      "After Batches\n",
      "Before Validation\n",
      "calculate F1 score\n",
      "3  Epoch  0  K\n",
      "411\n",
      "After Batches\n",
      "Before Validation\n",
      "calculate F1 score\n",
      "4  Epoch  0  K\n",
      "411\n",
      "After Batches\n",
      "Before Validation\n",
      "calculate F1 score\n",
      "5  Epoch  0  K\n",
      "411\n",
      "After Batches\n",
      "Before Validation\n",
      "calculate F1 score\n",
      "6  Epoch  0  K\n",
      "411\n",
      "After Batches\n",
      "Before Validation\n",
      "calculate F1 score\n",
      "7  Epoch  0  K\n",
      "411\n",
      "After Batches\n",
      "Before Validation\n",
      "calculate F1 score\n",
      "8  Epoch  0  K\n",
      "411\n",
      "After Batches\n",
      "Before Validation\n",
      "calculate F1 score\n",
      "9  Epoch  0  K\n",
      "411\n",
      "After Batches\n",
      "Before Validation\n",
      "calculate F1 score\n",
      "10  Epoch  0  K\n",
      "411\n",
      "After Batches\n",
      "Before Validation\n",
      "calculate F1 score\n",
      "11  Epoch  0  K\n",
      "411\n",
      "After Batches\n",
      "Before Validation\n",
      "calculate F1 score\n",
      "12  Epoch  0  K\n",
      "411\n",
      "After Batches\n",
      "Before Validation\n",
      "calculate F1 score\n"
     ]
    }
   ],
   "source": [
    "run ./doduo/train_multi.py --task gittables_30 --max_length 256 --lr 0.001"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98277279",
   "metadata": {},
   "source": [
    "#### Installation aller benötigten Ressourcen; zu beachten vom Original wurde die Transformer version auf 4.6.0 gehoben\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd4479e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.20.2 in /home/wi20-sl02/.local/lib/python3.9/site-packages (from -r ./requirements.txt (line 1)) (1.20.2)\n",
      "Requirement already satisfied: pandas==1.2.4 in /home/wi20-sl02/.local/lib/python3.9/site-packages (from -r ./requirements.txt (line 2)) (1.2.4)\n",
      "Requirement already satisfied: scikit-learn==0.24.1 in /home/wi20-sl02/.local/lib/python3.9/site-packages (from -r ./requirements.txt (line 3)) (0.24.1)\n",
      "Requirement already satisfied: scipy==1.6.2 in /home/wi20-sl02/.local/lib/python3.9/site-packages (from -r ./requirements.txt (line 4)) (1.6.2)\n",
      "Requirement already satisfied: torch==1.8.1 in /home/wi20-sl02/.local/lib/python3.9/site-packages (from -r ./requirements.txt (line 5)) (1.8.1)\n",
      "Collecting transformers==4.6.0\n",
      "  Downloading transformers-4.6.0-py3-none-any.whl (2.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 8.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /home/wi20-sl02/.local/lib/python3.9/site-packages (from pandas==1.2.4->-r ./requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/wi20-sl02/.local/lib/python3.9/site-packages (from pandas==1.2.4->-r ./requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/wi20-sl02/.local/lib/python3.9/site-packages (from scikit-learn==0.24.1->-r ./requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/wi20-sl02/.local/lib/python3.9/site-packages (from scikit-learn==0.24.1->-r ./requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions in /home/wi20-sl02/.local/lib/python3.9/site-packages (from torch==1.8.1->-r ./requirements.txt (line 5)) (4.5.0)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from transformers==4.6.0->-r ./requirements.txt (line 6)) (3.0.12)\n",
      "Collecting huggingface-hub==0.0.8\n",
      "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers==4.6.0->-r ./requirements.txt (line 6)) (2.25.1)\n",
      "Requirement already satisfied: sacremoses in /home/wi20-sl02/.local/lib/python3.9/site-packages (from transformers==4.6.0->-r ./requirements.txt (line 6)) (0.0.53)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/wi20-sl02/.local/lib/python3.9/site-packages (from transformers==4.6.0->-r ./requirements.txt (line 6)) (4.65.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/wi20-sl02/.local/lib/python3.9/site-packages (from transformers==4.6.0->-r ./requirements.txt (line 6)) (2023.5.5)\n",
      "Requirement already satisfied: packaging in /home/wi20-sl02/.local/lib/python3.9/site-packages (from transformers==4.6.0->-r ./requirements.txt (line 6)) (23.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/wi20-sl02/.local/lib/python3.9/site-packages (from transformers==4.6.0->-r ./requirements.txt (line 6)) (0.10.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas==1.2.4->-r ./requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: click in /home/wi20-sl02/.local/lib/python3.9/site-packages (from sacremoses->transformers==4.6.0->-r ./requirements.txt (line 6)) (8.1.3)\n",
      "Installing collected packages: huggingface-hub, transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.5.1\n",
      "    Uninstalling transformers-4.5.1:\n",
      "      Successfully uninstalled transformers-4.5.1\n",
      "Successfully installed huggingface-hub-0.0.8 transformers-4.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57f716c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'platform': 'Linux', 'platform-release': '5.10.0-18-amd64', 'platform-version': '#1 SMP Debian 5.10.140-1 (2022-09-02)', 'architecture': 'x86_64', 'hostname': 'volta01', 'ip-address': '10.50.15.140', 'mac-address': 'ac:1f:6b:41:9f:da', 'processor': '', 'ram': '252 GB'}\n",
      "True\n",
      "4\n",
      "0\n",
      "Tesla V100-SXM2-32GB\n",
      "Tesla V100-SXM2-32GB\n",
      "Tesla V100-SXM2-32GB\n",
      "Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "#Shamelessly combined from google and other stackoverflow like sites to form a single function\n",
    "# Outputs the systems underlying hardware\n",
    "\n",
    "import platform,socket,re,uuid,json,psutil,logging\n",
    "\n",
    "def getSystemInfo():\n",
    "    try:\n",
    "        info={}\n",
    "        info['platform']=platform.system()\n",
    "        info['platform-release']=platform.release()\n",
    "        info['platform-version']=platform.version()\n",
    "        info['architecture']=platform.machine()\n",
    "        info['hostname']=socket.gethostname()\n",
    "        info['ip-address']=socket.gethostbyname(socket.gethostname())\n",
    "        info['mac-address']=':'.join(re.findall('..', '%012x' % uuid.getnode()))\n",
    "        info['processor']=platform.processor()\n",
    "        info['ram']=str(round(psutil.virtual_memory().total / (1024.0 **3)))+\" GB\"\n",
    "        return json.dumps(info)\n",
    "    except Exception as e:\n",
    "        logging.exception(e)\n",
    "\n",
    "print(json.loads(getSystemInfo()))\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.get_device_name(1))\n",
    "print(torch.cuda.get_device_name(2))\n",
    "print(torch.cuda.get_device_name(3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
